---
title: "é¡ä¼¼ç”»åƒæ¤œç´¢ãƒ„ãƒ¼ãƒ«ã‚’ä½œã£ã¦ã¿ã‚‹ (3) ç‰¹å¾´åŒ– ãã®2"
emoji: "ğŸ”"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["machinelearning", "deeplearning", "computervision", "python", "æ¤œç´¢"]
published: true
---

# ç›®æ¬¡

* [é¡ä¼¼ç”»åƒæ¤œç´¢ãƒ„ãƒ¼ãƒ«ã‚’ä½œã£ã¦ã¿ã‚‹ (1) åºç« ](202105-similar-search-1)
* [é¡ä¼¼ç”»åƒæ¤œç´¢ãƒ„ãƒ¼ãƒ«ã‚’ä½œã£ã¦ã¿ã‚‹ (2) ç‰¹å¾´åŒ– ãã®1](202105-similar-search-2)
* é¡ä¼¼ç”»åƒæ¤œç´¢ãƒ„ãƒ¼ãƒ«ã‚’ä½œã£ã¦ã¿ã‚‹ (3) ç‰¹å¾´åŒ– ãã®2ï¼ˆæœ¬è¨˜äº‹ï¼‰

# ç‰¹å¾´åŒ–

[å‰å›](202105-similar-search-2)ã€MobileNet V3ã®å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ONNXãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›ã™ã‚‹ã¨ã“ã‚ã¾ã§ã‚’å®Ÿæ–½ã—ã¾ã—ãŸã€‚

ä»Šå›ã¯ã€æ¤œç´¢å¯¾è±¡ã§ã‚ã‚‹ç´„10ä¸‡æšã®ç”»åƒã«ã¤ã„ã¦ç‰¹å¾´é‡ã‚’å–å¾—ã—ã¦ã¿ãŸã„ã¨æ€ã„ã¾ã™ã€‚

# ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã®ä½œæˆ

ã¾ãšã¯ã€ç‰¹å¾´é‡ã‚’å–å¾—ã™ã‚‹ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€è¦§ã‚’ä½œæˆã—ã¾ã™ã€‚10ä¸‡æšã‚‚ã‚ã‚‹ã¨ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã®å–å¾—ã«åœ°å‘³ã«æ™‚é–“ãŒæ›ã‹ã‚‹ã®ã§ã€äºˆã‚ä¸€è¦§ã‚’ç”Ÿæˆã—ã¦ãŠãã¾ã™ã€‚

```
$ cd /mnt/media/
$ find object -type f -name "*.jpg" | sort > objects.txt
$ wc -l objects.txt
100381 objects.txt

$ head -n 5 objects.txt
object/00/00/0000bada96b0c1c131ebdf41c37964f308cb21d3.jpg
object/00/01/0001594e435e50bf781a99d1de4446fde176fc03.jpg
object/00/03/000313d295f268775cf28a6322272b93def124f2.jpg
object/00/03/00036628c1855fc8648649c61bff4edc3b9760c4.jpg
object/00/03/0003af0e37f9fbac7180fad7836a0223dd4ac4f0.jpg
```

# ç‰¹å¾´é‡ã®å–å¾—

ä»Šå›ã¯ã€ä»¥ä¸‹ã®Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ã§ç‰¹å¾´é‡ã‚’å–å¾—ã—ã¾ã—ãŸã€‚å¤§ã¾ã‹ãªæµã‚Œã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

1. `objects.txt`ã‹ã‚‰ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’èª­ã¿è¾¼ã‚€ã€‚
2. ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã™ã‚‹ã€‚ï¼ˆç°¡æ˜“ä¸¦åˆ—åŒ–ã®ãŸã‚ï¼‰
3. ONNXãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã€‚
4. å„ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã«ã¤ã„ã¦:
    1. å‡ºåŠ›å…ˆã®ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    2. å‡ºåŠ›å…ˆã®ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãŒæ—¢ã«å­˜åœ¨ã—ãŸã‚‰ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã€‚ï¼ˆç°¡æ˜“ä¸¦åˆ—åŒ–ã®ãŸã‚ï¼‰
    3. ç”»åƒã‚’èª­ã¿è¾¼ã‚€ã€‚
    4. ç”»åƒã‚’æ•´å½¢ã™ã‚‹ã€‚
    5. ç‰¹å¾´é‡ã‚’å–å¾—ã™ã‚‹ã€‚ï¼ˆæ¨è«–ã™ã‚‹ï¼‰
    6. ç‰¹å¾´é‡ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€ã€‚

```py:extract_all.py
#!/usr/bin/env python3

import pathlib
import random

import numpy as np
import onnxruntime
import PIL.Image

MEDIA_DIR = pathlib.Path("/mnt/media")
FEATURE_DIR = pathlib.Path("/mnt/feature")
ONNX_MODEL_PATH = pathlib.Path("/mnt/model/mobilenet_v3_large_100_224_feature_vector_v5.onnx")


def make_nested_id_path(dir, id, ext=""):
    return dir / id[0:2] / id[2:4] / (id + ext)


image_list_path = MEDIA_DIR / "objects.txt"
feature_base_dir = FEATURE_DIR / ONNX_MODEL_PATH.stem

with image_list_path.open("r") as file:
    image_paths = [MEDIA_DIR / path.rstrip() for path in file.readlines()]
print(len(image_paths))

random.shuffle(image_paths)

onnx_session = onnxruntime.InferenceSession(str(ONNX_MODEL_PATH))

for image_path in image_paths:
    print(image_path)
    object_id = image_path.name
    feature_path = make_nested_id_path(feature_base_dir, object_id, ".npy")
    print(feature_path)
    if feature_path.exists():
        print("skip")
        continue

    image = PIL.Image.open(image_path)
    image = image.convert("RGB")
    image = image.resize((224, 224))
    image = np.array(image, dtype=np.float32)
    image = image / 255

    feature = onnx_session.run(["feature_vector"], {"inputs:0": np.expand_dim(image, 0)})[0][0]
    feature_path.parent.mkdir(parents=True, exist_ok=True)
    np.save(feature_path, feature)
```

ä¸Šè¨˜ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã¯æ„šç›´ã«å‡¦ç†ã‚’è¡Œã£ã¦ãŠã‚Šã€ç‰¹ã«ä¸¦åˆ—åŒ–ãªã©ã¯è¡Œã£ã¦ã„ã¾ã›ã‚“ã€‚
ãŸã ã€ã€Œä¸€è¦§ã®ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã€ã€ã€ŒçµæœãŒå­˜åœ¨ã—ãŸã‚‰ã‚¹ã‚­ãƒƒãƒ—ã€ã¨ã„ã†å‡¦ç†ã‚’çµ„ã¿è¾¼ã‚“ã§ã„ã‚‹ã®ã§ã€è¤‡æ•°ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’èµ·å‹•ã™ã‚‹ã ã‘ã§ç°¡æ˜“çš„ã«ä¸¦åˆ—åŒ–ã§ãã¾ã™ã€‚
ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰åŒ–ã€æ¨è«–ã®ãƒãƒƒãƒåŒ–ãªã©ã‚’è¡Œãˆã°ã‚‚ã£ã¨é«˜é€Ÿã«å‡¦ç†ã§ããã†ã§ã™ãŒã€ä»Šå›ã¯ç°¡å˜ã§ç¢ºå®Ÿãªæ–¹æ³•ã‚’é¸ã³ã¾ã—ãŸã€‚

```
$ tmux
[1]$ ./extract_all.py
[2]$ ./extract_all.py
[3]$ ./extract_all.py
[4]$ ./extract_all.py
[5]$ ./extract_all.py
[6]$ ./extract_all.py
[7]$ ./extract_all.py
[8]$ ./extract_all.py
```

ä»Šå›ã¯å¾ã€…ã«ãƒ—ãƒ­ã‚»ã‚¹æ•°ã‚’å¢—ã‚„ã—ã€æœ€çµ‚çš„ã«8ãƒ—ãƒ­ã‚»ã‚¹ã§ä¸¦åˆ—å®Ÿè¡Œã—ã¾ã—ãŸã€‚ãƒ—ãƒ­ã‚»ã‚¹ã‚ãŸã‚Šã®GPUãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã¯350MBã»ã©ã§ã—ãŸã€‚
ç´„10ä¸‡æšã®ç‰¹å¾´é‡ã«ã¤ã„ã¦ã€15åˆ†ä»¥å†…ã«å‡¦ç†ã‚’çµ‚ãˆã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸã€‚

# ç‰¹å¾´é‡ã®çµåˆ

ä¸Šè¨˜ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã€ç”»åƒ1æšã«å¯¾ã—ã¦1ã¤ã®ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸã€‚
ãŸã ã€ã“ã®ã¾ã¾ã§ã¯å‡¦ç†ã—ã¥ã‚‰ã„ã®ã§ã€ä¸€å®šå˜ä½ï¼ˆã“ã“ã§ã¯1ä¸‡æšï¼‰ã§ã¾ã¨ã‚ã‚‹ã“ã¨ã«ã—ã¾ã™ã€‚

ç‰¹å¾´é‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

```py:concat.py
#!/usr/bin/env python3

import pathlib

import numpy as np

FEATURE_DIR = pathlib.Path("/mnt/feature/mobilenet_v3_large_100_224_feature_vector_v5")

feature_paths = sorted(FEATURE_DIR.glob("*/*/*.npy"))
print(len(feature_paths))

maximum = 10000

object_ids = []
features = []
for feature_path in feature_paths[0:maximum]:
    print(feature_path)
    object_id = feature_path.stem
    feature = np.load(feature_path)
    object_ids.append(object_id)
    features.append(feature)

object_ids = np.array(object_ids)
features = np.array(features)

for output_index in range(20):
    object_ids_path = FEATURE_DIR / "{:04d}.object_ids.npy".format(output_index)
    features_path = FEATURE_DIR / "{:04d}.features.npy".format(output_index)
    if object_ids_path.exists():
        continue

    np.save(object_ids_path, object_ids)
    np.save(features_path, features)

    for feature_path in feature_paths[0:maximum]:
        feature_path.unlink()

    break
```

ä¸Šè¨˜ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’11å›å®Ÿè¡Œã—ã€`*.features.npy`ã€`*.object_ids.npy`ã®ãƒšã‚¢ã‚’11çµ„ä½œæˆã—ã¾ã—ãŸã€‚

```
# 11å›å®Ÿè¡Œã™ã‚‹
$ ./concat.py

$ cd /mnt/feature/mobilenet_v3_large_100_224_feature_vector_v5/
$ ls -lh *.npy
-rw-r--r-- 1 1000 1000  49M May 23 10:42 0000.features.npy
-rw-r--r-- 1 1000 1000 1.7M May 23 10:42 0000.object_ids.npy
-rw-r--r-- 1 1000 1000  49M May 23 10:43 0001.features.npy
-rw-r--r-- 1 1000 1000 1.7M May 23 10:43 0001.object_ids.npy
-rw-r--r-- 1 1000 1000  49M May 23 10:43 0002.features.npy
-rw-r--r-- 1 1000 1000 1.7M May 23 10:43 0002.object_ids.npy
-rw-r--r-- 1 1000 1000  49M May 23 10:43 0003.features.npy
-rw-r--r-- 1 1000 1000 1.7M May 23 10:43 0003.object_ids.npy
-rw-r--r-- 1 1000 1000  49M May 23 10:43 0004.features.npy
-rw-r--r-- 1 1000 1000 1.7M May 23 10:43 0004.object_ids.npy
-rw-r--r-- 1 1000 1000  49M May 23 10:43 0005.features.npy
-rw-r--r-- 1 1000 1000 1.7M May 23 10:43 0005.object_ids.npy
-rw-r--r-- 1 1000 1000  49M May 23 10:43 0006.features.npy
-rw-r--r-- 1 1000 1000 1.7M May 23 10:43 0006.object_ids.npy
-rw-r--r-- 1 1000 1000  49M May 23 10:43 0007.features.npy
-rw-r--r-- 1 1000 1000 1.7M May 23 10:43 0007.object_ids.npy
-rw-r--r-- 1 1000 1000  49M May 23 10:43 0008.features.npy
-rw-r--r-- 1 1000 1000 1.7M May 23 10:43 0008.object_ids.npy
-rw-r--r-- 1 1000 1000  49M May 23 10:44 0009.features.npy
-rw-r--r-- 1 1000 1000 1.7M May 23 10:44 0009.object_ids.npy
-rw-r--r-- 1 1000 1000 1.9M May 23 10:44 0010.features.npy
-rw-r--r-- 1 1000 1000  66K May 23 10:44 0010.object_ids.npy
```

çµåˆå¾Œã®ç‰¹å¾´é‡ã¯ã€1ä¸‡æšã‚ãŸã‚Šç´„50MBã«ãªã‚Šã¾ã—ãŸã€‚
