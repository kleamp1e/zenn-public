---
title: "けしからん画像分類器を作ってみる (6) データ管理 その2"
emoji: "👙"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["machinelearning", "deeplearning", "computervision", "python"]
published: false
---

# 目次

* [けしからん画像分類器を作ってみる (1) 序章](202102-pornography-classifier-1)
* [けしからん画像分類器を作ってみる (2) データ収集 その1](202102-pornography-classifier-2)
* [けしからん画像分類器を作ってみる (3) データ収集 その2](202102-pornography-classifier-3)
* [けしからん画像分類器を作ってみる (4) データ収集 その3](202103-pornography-classifier-4)
* [けしからん画像分類器を作ってみる (5) データ管理 その1](202103-pornography-classifier-5)
* けしからん画像分類器を作ってみる (6) データ管理 その2（本記事）

# 続 データ管理

[前回](202103-pornography-classifier-5)に続き、学習に使用するデータの管理について述べたいと思います。

データ管理に関して工夫した点、上手くいった点などは以下の通りです。（再掲）

* 使用するハッシュアルゴリズムを1つに絞りました
* URLはハッシュ値で管理しました
* データはハッシュ値で管理しました
* データはGitで管理しました
* データはNFSで管理しました
* データはOverlayFSを介して参照しました

前回は前半3つを紹介したので、今回は後半3つについて書きたいと思います。

# データはGitで管理しました

収集したデータ（HTML、画像、動画、それらのメタ情報）は、分散バージョン管理システムである「Git」で管理しました。
理由は以下の通りです。

* ソースコードの管理で既にGitを使っており、使用するツールを増やさずに済む。
* 個人の写真の管理にも使用しており、数十GBのデータを管理する実績があった。
* 差分バックアップが行いやすい。（他のマシンに転送しやすい）
* タグを打つことができる。

Gitリポジトリは、データを収集するサイト毎に分割しました。サイト毎の`.git`ディレクトリのサイズは以下の通りです。

|サイト|容量|
|:---|---:|
| サイトC | 32 GB |
| サイトI | 8.6 GB |
| サイトO | 15 GB |
| サイトS | 69 GB |
| サイトX | 0.9 GB |
| 合計 | 125 GB |

一方でデメリットもいくつかあります。

* `.git`ディレクトリと作業ディレクトリの両方でストレージ容量を使用するため、容量効率が悪い。
* 転送時の圧縮に時間がかかる。（JPEGやMP4はそもそもそれ以上の圧縮は期待できない）
    * 転送時の圧縮を無効化する方法があると良いのですが、見つけられませんでした。

# データはNFSで管理しました

データを収集するクローラはDockerコンテナとして動作し、そのDockerコンテナにデータを格納しているディレクトリをNFSでマウントしました。
上記の通りデータは125GBと大きいため、移動やコピーにはそれなりの時間が掛かります。
NFSでマウントすることでデータの移動やコピーを最小限にでき、かつ好きな場所（マシン）でクローラを動かすことができます。

実際、GPUが搭載されたLinuxマシンにデータを置き、手元のMacBook Proからマウントしつつ開発を進めました。
ネットワークを経由したストレージI/Oなので速度は期待できませんが、そもそもインターネットからのダウンロードの方が圧倒的に遅いので、たいして気になりませんでした。

# データはOverlayFSを介して参照しました
