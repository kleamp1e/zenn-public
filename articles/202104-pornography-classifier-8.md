---
title: "ã‘ã—ã‹ã‚‰ã‚“ç”»åƒåˆ†é¡å™¨ã‚’ä½œã£ã¦ã¿ã‚‹ (8) å­¦ç¿’ ãã®2"
emoji: "ğŸ‘™"
type: "idea" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["machinelearning", "deeplearning", "computervision", "python", "keras"]
published: true
---

# ç›®æ¬¡

* [ã‘ã—ã‹ã‚‰ã‚“ç”»åƒåˆ†é¡å™¨ã‚’ä½œã£ã¦ã¿ã‚‹ (1) åºç« ](202102-pornography-classifier-1)
* [ã‘ã—ã‹ã‚‰ã‚“ç”»åƒåˆ†é¡å™¨ã‚’ä½œã£ã¦ã¿ã‚‹ (2) ãƒ‡ãƒ¼ã‚¿åé›† ãã®1](202102-pornography-classifier-2)
* [ã‘ã—ã‹ã‚‰ã‚“ç”»åƒåˆ†é¡å™¨ã‚’ä½œã£ã¦ã¿ã‚‹ (3) ãƒ‡ãƒ¼ã‚¿åé›† ãã®2](202102-pornography-classifier-3)
* [ã‘ã—ã‹ã‚‰ã‚“ç”»åƒåˆ†é¡å™¨ã‚’ä½œã£ã¦ã¿ã‚‹ (4) ãƒ‡ãƒ¼ã‚¿åé›† ãã®3](202103-pornography-classifier-4)
* [ã‘ã—ã‹ã‚‰ã‚“ç”»åƒåˆ†é¡å™¨ã‚’ä½œã£ã¦ã¿ã‚‹ (5) ãƒ‡ãƒ¼ã‚¿ç®¡ç† ãã®1](202103-pornography-classifier-5)
* [ã‘ã—ã‹ã‚‰ã‚“ç”»åƒåˆ†é¡å™¨ã‚’ä½œã£ã¦ã¿ã‚‹ (6) ãƒ‡ãƒ¼ã‚¿ç®¡ç† ãã®2](202103-pornography-classifier-6)
* [ã‘ã—ã‹ã‚‰ã‚“ç”»åƒåˆ†é¡å™¨ã‚’ä½œã£ã¦ã¿ã‚‹ (7) å­¦ç¿’ ãã®1](202104-pornography-classifier-7)
* ã‘ã—ã‹ã‚‰ã‚“ç”»åƒåˆ†é¡å™¨ã‚’ä½œã£ã¦ã¿ã‚‹ (8) å­¦ç¿’ ãã®2ï¼ˆæœ¬è¨˜äº‹ï¼‰
* [ã‘ã—ã‹ã‚‰ã‚“ç”»åƒåˆ†é¡å™¨ã‚’ä½œã£ã¦ã¿ã‚‹ (9) æ¨è«–](202104-pornography-classifier-9)
* ç•ªå¤–ç·¨:
    * [EfficientNet B0ã€œB7ã§ç”»åƒåˆ†é¡å™¨ã‚’è»¢ç§»å­¦ç¿’ã—ã¦ã¿ã‚‹](202104-efficientnet)

# ç¶š å­¦ç¿’

[å‰å›](202104-pornography-classifier-7)ã¯ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²ã¾ã§ã‚’è¡Œã„ã¾ã—ãŸã€‚ä»Šå›ã¯å®Ÿéš›ã«å­¦ç¿’ã‚’è¡Œã£ã¦ã„ãã¾ã™ã€‚

# çµè«–

æœ€åˆã«çµè«–ã‚’æ›¸ã„ã¦ãŠãã¨ã€ç²¾åº¦ï¼ˆAccuracyï¼‰ãŒ85%ç¨‹åº¦ã®ç”»åƒåˆ†é¡ãƒ¢ãƒ‡ãƒ«ã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸã€‚
åˆå›ãªã®ã§ã»ã¨ã‚“ã©å·¥å¤«ã¯ã—ã¦ãŠã‚‰ãšã€ã‹ãªã‚Šã‚·ãƒ³ãƒ—ãƒ«ãªæ§‹æˆã§ã™ã€‚æ§˜ã€…ãªæ‰‹æ³•ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§ã€ã•ã‚‰ã«æ•°%ã¯ç²¾åº¦ã‚’é«˜ã‚ã‚‰ã‚Œãã†ãªæ°—ãŒã—ã¦ã„ã¾ã™ã€‚

# ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†

Kerasã‚’ä½¿ã£ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã™ã‚‹ã«ã‚ãŸã‚Šã€ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«`tf.keras.preprocessing.image.ImageDataGenerator`ã‚’ä½¿ç”¨ã—ã¾ã—ãŸã€‚ï¼ˆæ‰‹æŠœãã®ãŸã‚ã«ï¼‰

`ImageDataGenerator`ã¯ç‰¹å®šã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ãŒå‰æã¨ãªã£ã¦ã„ã¾ã™ã®ã§ã€æ—¢å­˜ã®ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ãã®æ§‹é€ ã«é…ç½®ã—ã¾ã™ã€‚
ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹ã®ã¯ç„¡é§„ãªã®ã§ã€ä»Šå›ã¯ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ã‚’ä½œæˆã—ã¦ã„ã¾ã™ã€‚

å…·ä½“çš„ã«ã¯`/tmp/cache/pornography/<ã‚¿ã‚¤ãƒ—>/<ãƒ©ãƒ™ãƒ«>/ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆID.jpg`ã¿ãŸã„ãªãƒ‘ã‚¹ã§ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ã‚’ä½œæˆã—ã¾ã™ã€‚
ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

```py:make_link.py
#!/usr/bin/env python3

import os
import pathlib

import pandas as pd

def make_nested_id_path(dir, id, ext=""):
    return dir / id[0:2] / id[2:4] / (id + ext)

MEDIA_DIR = pathlib.Path(os.environ.get("MEDIA_DIR"))
OBJECT_DIR = MEDIA_DIR / "object"
CACHE_DIR = pathlib.Path("/tmp/cache/pornography")
CACHE_DIR.mkdir(parents=True, exist_ok=True)

df = pd.read_csv("split_label.csv")

for type in ["train", "test", "validation"]:
  for index, (object_id, value) in df[["objectId", "value"]][df["type"] == type].iterrows():
      image_path = make_nested_id_path(OBJECT_DIR, object_id)
      target_path = CACHE_DIR / type / str(value) / object_id
      target_path.parent.mkdir(parents=True, exist_ok=True)
      if not target_path.exists():
          target_path.symlink_to(image_path)
```

# å­¦ç¿’ã®ç’°å¢ƒ

å­¦ç¿’ã¯Dockerã‚³ãƒ³ãƒ†ãƒŠå†…ã§å®Ÿè¡Œã—ã¾ã—ãŸã€‚`Dockerfile`ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

```Dockerfile:Dockerfile
FROM nvidia/cuda:11.0.3-cudnn8-devel-ubuntu20.04
RUN apt-get update \
  && DEBIAN_FRONTEND=noninteractive apt-get install --yes --no-install-recommends \
    build-essential \
    ca-certificates \
    python3-dev \
    python3-pip \
    python3-setuptools \
    tzdata \
  && rm --recursive --force /var/lib/apt/lists/*
RUN python3 -m pip install --upgrade pip setuptools
WORKDIR /opt/app
COPY requirements.txt ./
RUN python3 -m pip install --requirement requirements.txt
ENV LANG C.UTF-8
ENV TZ Asia/Tokyo
```

ã¾ãŸã€`requirements.txt`ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚é–¢ä¿‚ã™ã‚‹ä¸»è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã¿è¨˜è¼‰ã—ã¦ã„ã¾ã™ã€‚

```:requirements.txt
numpy==1.19.5
pandas==1.2.3
Pillow==8.2.0
scipy==1.6.2
tensorflow-estimator==2.4.0
tensorflow-hub==0.11.0
tensorflow==2.4.1
```

ãªãŠã€NVIDIAã®GPUã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã€[NVIDIA Container Toolkit](https://github.com/NVIDIA/nvidia-docker)ãŒå¿…è¦ã§ã™ã€‚

# å­¦ç¿’

ã•ã¦ã€ã„ã‚ˆã„ã‚ˆå­¦ç¿’ã§ã™ã€‚ä¸»ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãªã©ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

* ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ï¼ˆBackboneï¼‰: EfficientNet B0
* ãƒ˜ãƒƒãƒ‰ï¼ˆHeadï¼‰: å…¨çµåˆå±¤ï¼ˆFC: Fully Connectedï¼‰ + Sigmoid
* ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ï¼ˆOptimizerï¼‰: Adam
* å…¥åŠ›ç”»åƒã‚µã‚¤ã‚º: 224x224
* ãƒãƒƒãƒã‚µã‚¤ã‚º: 512
* ã‚¨ãƒãƒƒã‚¯æ•°: 10

å­¦ç¿’ã«ä½¿ç”¨ã—ãŸã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

```py:train.py
#!/usr/bin/env python3

import datetime

import pandas as pd
import tensorflow as tf
import tensorflow_hub as hub

BATCH_SIZE = 512
TARGET_SIZE = (224, 224)
EPOCHS = 10

model = tf.keras.Sequential(
    [
        hub.KerasLayer(
            "https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1",
            trainable=False,
        ),
        tf.keras.layers.Dense(1, activation="sigmoid"),
    ]
)
model.build([None, 224, 224, 3])
model.compile(
    optimizer=tf.keras.optimizers.Adam(),
    loss="binary_crossentropy",
    metrics=["accuracy"],
)
model.summary()

train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=(1.0 / 255))
train_generator = train_datagen.flow_from_directory(
    "/tmp/cache/pornography/train",
    target_size=TARGET_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="binary",
)

validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=(1.0 / 255)
)
validation_generator = validation_datagen.flow_from_directory(
    "/tmp/cache/pornography/validation",
    target_size=TARGET_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="binary",
)

test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=(1.0 / 255))
test_generator = test_datagen.flow_from_directory(
    "/tmp/cache/pornography/test",
    target_size=TARGET_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="binary",
)

model.fit(
    x=train_generator,
    steps_per_epoch=train_generator.n // BATCH_SIZE,
    epochs=EPOCHS,
    workers=8,
    validation_data=validation_generator,
    validation_steps=validation_generator.n // BATCH_SIZE,
    callbacks=[
        tf.keras.callbacks.TensorBoard(
            log_dir="log/" + datetime.datetime.now().strftime("%Y%m%d_%H%M%S"),
            histogram_freq=1,
        )
    ],
)

model.evaluate(x=test_generator, steps=(test_generator.n // BATCH_SIZE), workers=8)

model.save("model.h5")
```

å®Ÿè¡Œçµæœã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚å­¦ç¿’æ™‚é–“ã¯ç´„10åˆ†ã§ã—ãŸã€‚

```
$ ./src/train.py
...
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
keras_layer (KerasLayer)     (None, 1280)              4049564
_________________________________________________________________
dense (Dense)                (None, 1)                 1281
=================================================================
Total params: 4,050,845
Trainable params: 1,281
Non-trainable params: 4,049,564
_________________________________________________________________
Found 19658 images belonging to 2 classes.
Found 1494 images belonging to 2 classes.
Found 1488 images belonging to 2 classes.
...
Epoch 1/10
38/38 [==============================] - 68s 1s/step - loss: 0.6039 - accuracy: 0.6356 - val_loss: 0.4211 - val_accuracy: 0.8115
Epoch 2/10
38/38 [==============================] - 54s 1s/step - loss: 0.3425 - accuracy: 0.8594 - val_loss: 0.3497 - val_accuracy: 0.8447
Epoch 3/10
38/38 [==============================] - 52s 1s/step - loss: 0.3100 - accuracy: 0.8672 - val_loss: 0.3444 - val_accuracy: 0.8486
Epoch 4/10
38/38 [==============================] - 53s 1s/step - loss: 0.2925 - accuracy: 0.8726 - val_loss: 0.3309 - val_accuracy: 0.8506
Epoch 5/10
38/38 [==============================] - 53s 1s/step - loss: 0.2813 - accuracy: 0.8815 - val_loss: 0.3483 - val_accuracy: 0.8457
Epoch 6/10
38/38 [==============================] - 54s 1s/step - loss: 0.2754 - accuracy: 0.8820 - val_loss: 0.3282 - val_accuracy: 0.8545
Epoch 7/10
38/38 [==============================] - 52s 1s/step - loss: 0.2696 - accuracy: 0.8855 - val_loss: 0.3247 - val_accuracy: 0.8564
Epoch 8/10
38/38 [==============================] - 53s 1s/step - loss: 0.2603 - accuracy: 0.8900 - val_loss: 0.3111 - val_accuracy: 0.8672
Epoch 9/10
38/38 [==============================] - 53s 1s/step - loss: 0.2597 - accuracy: 0.8881 - val_loss: 0.3178 - val_accuracy: 0.8564
Epoch 10/10
38/38 [==============================] - 53s 1s/step - loss: 0.2523 - accuracy: 0.8911 - val_loss: 0.3320 - val_accuracy: 0.8477
2/2 [==============================] - 8s 1s/step - loss: 0.3170 - accuracy: 0.8535
```

è‰¯ã„æ„Ÿã˜ã«å­¦ç¿’ãŒé€²ã‚“ã§ã„ã¾ã™ã­ã€‚ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«ã‚ˆã‚‹è©•ä¾¡ã§ã¯ã€ç²¾åº¦ç´„85%ã¨ãªã‚Šã¾ã—ãŸã€‚

TensorBoardã§ç¢ºèªã—ãŸç²¾åº¦ã®ãƒãƒ£ãƒ¼ãƒˆã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

![](https://storage.googleapis.com/zenn-user-upload/kzc5xkuuasgxfsj2up4st4ozc4lf)

åŒã˜ãã€Lossã®ãƒãƒ£ãƒ¼ãƒˆã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

![](https://storage.googleapis.com/zenn-user-upload/wn45s1d1g0p8617mf3xgobx4wha4)

# ä»Šå¾Œã®å±•æœ›

ç‰¹ã«å·¥å¤«ãªãæ¯”è¼ƒçš„é«˜ç²¾åº¦ãªç”»åƒåˆ†é¡ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸã€‚ãŸã ã€ã‚¿ã‚¹ã‚¯ã¨ã—ã¦ã¯å‰²ã¨å˜ç´”ãªæ–¹ã ã¨æ€ã†ã®ã§ã€å°‘ãªãã¨ã‚‚ç²¾åº¦90%ã¯è¶ŠãˆãŸã„ã¨ã“ã‚ã§ã™ã€‚
å·¥å¤«ã§ããã†ãªç‚¹ã‚’ã„ãã¤ã‹ä¸Šã’ã¦ã¿ã¾ã™ã€‚

* ç²¾åº¦å‘ä¸Šã®ãŸã‚ã«:
    * **ã‚¨ãƒãƒƒã‚¯æ•°ã‚’å¢—ã‚„ã™:** ãƒãƒ£ãƒ¼ãƒˆã‚’è¦‹ã‚‹é™ã‚Šã€ã‚¨ãƒãƒƒã‚¯æ•°ã‚’å¢—ã‚„ã›ã°ã¾ã ä¼¸ã³ãã†ãªæ°—ãŒã—ã¾ã™ã€‚1ã‚¨ãƒãƒƒã‚¯1åˆ†ã»ã©ã§çµ‚ã‚ã‚‹ã®ã§ã€æ¯”è¼ƒçš„ä½ã‚³ã‚¹ãƒˆã§ã™ã€‚
    * **å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã™:** ãƒ‡ãƒ¼ã‚¿ã‚’å¢—ã‚„ã›ã°ç²¾åº¦ãŒä¸ŠãŒã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãŸã ã€ãªã‹ãªã‹é«˜ã‚³ã‚¹ãƒˆã§ã™ã€‚
    * **ãƒ‡ãƒ¼ã‚¿ã®è³ªã‚’é«˜ã‚ã‚‹:** åˆæœŸã«ãƒ©ãƒ™ãƒ«ä»˜ã‘ã—ãŸãƒ‡ãƒ¼ã‚¿ã¯ã€ãƒ©ãƒ™ãƒ«ä»˜ã‘åŸºæº–ãŒæ˜ç¢ºã§ç„¡ã‹ã£ãŸãŸã‚ã€è³ªã®æ‚ªã„ãƒ©ãƒ™ãƒ«ã¨ãªã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã™ã¹ã¦ã®ãƒ©ãƒ™ãƒ«ã‚’è¦‹ç›´ã™ã“ã¨ã§ç²¾åº¦ã®å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™ã€‚ãŸã ã—ã€ã“ã‚Œã‚‚é«˜ã‚³ã‚¹ãƒˆã§ã™ã€‚
    * **ã‚¯ãƒ©ã‚¹ã®åã‚Šã‚’è€ƒæ…®ã™ã‚‹:** ä»Šå›ã¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã‚‹ã€Œã‘ã—ã‹ã‚‰ã‚“ç”»åƒã€ãŒã€Œã‘ã—ã‹ã‚‰ã‚“ããªã„ç”»åƒã€ã®ç´„2å€å­˜åœ¨ã—ã€ä¸å‡è¡¡ãŒç”Ÿã˜ã¦ã„ã¾ã™ã€‚ä¸å‡è¡¡ã‚’è€ƒæ…®ã™ã‚‹ã“ã¨ã§ç²¾åº¦ã®å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™ã€‚
    * **ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆData Augmentationï¼‰ã™ã‚‹:** åè»¢ã‚„å›è»¢ã€ãƒã‚¤ã‚ºã‚’åŠ ãˆã‚‹ãªã©ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’æ°´å¢—ã—ã™ã‚‹ã“ã¨ã§ç²¾åº¦ãŒå‘ä¸Šã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚`ImageDataGenerator`ã‚’ä½¿ã£ã¦ã„ã‚‹ã®ã§æ‰‹è»½ã«è©¦ã™ã“ã¨ãŒã§ãã¾ã™ã€‚
    * **B0ã‚ˆã‚Šå¤§ãã„ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹:** EfficientNetã«ã¯B0ã‹ã‚‰B7ã¾ã§ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ãŒã‚ã‚Šã€æ•°å­—ãŒå¤§ãã„ã»ã©å¤§è¦æ¨¡ï¼ˆã ã‘ã‚Œã©å‡¦ç†è² è·ã‚‚é«˜ã„ï¼‰ã¨ãªã‚Šã¾ã™ã€‚ã‚ˆã‚Šå¤§ããªãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›´ã™ã‚‹ã“ã¨ã§ã€ç²¾åº¦ãŒå‘ä¸Šã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
    * **ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹:** ä»Šå›ã¯ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³éƒ¨åˆ†ã¯å­¦ç¿’ã›ãšã€å˜ãªã‚‹ç‰¹å¾´é‡æŠ½å‡ºå™¨ã¨ã—ã¦ä½¿ç”¨ã—ã€ãƒ˜ãƒƒãƒ‰ã®ã¿ã‚’å­¦ç¿’ã—ã¾ã—ãŸã€‚ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã‚‚å«ã‚ã¦å­¦ç¿’ã™ã‚‹ã“ã¨ã§ç²¾åº¦ã®å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™ã€‚
* é«˜é€ŸåŒ–ã®ãŸã‚ã«:
    * **ç”»åƒã‚’ã™ã¹ã¦ãƒ¡ãƒ¢ãƒªã«èª­ã¿è¾¼ã‚“ã§ãŠã:** ä»Šå›ä½¿ç”¨ã—ãŸç”»åƒã¯ç´„2ä¸‡æšã¨æ¯”è¼ƒçš„å°‘ãªãã€ç”»åƒã‚µã‚¤ã‚ºã‚‚å°ã•ã„ãŸã‚4GBã«åã¾ã‚Šã¾ã™ã€‚ã™ã¹ã¦ã®ç”»åƒã‚’äºˆã‚ãƒ¡ãƒ¢ãƒªã«èª­ã¿è¾¼ã‚“ã§ãŠãã“ã¨ã§é«˜é€ŸåŒ–ãŒæœŸå¾…ã§ãã¾ã™ã€‚
    * **äº‹å‰ã«ç”»åƒã‚’ç¸®å°ã™ã‚‹:** ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã¸ã®å…¥åŠ›ã¯224x224ã¨æ¯”è¼ƒçš„å°ã•ã„ã‚µã‚¤ã‚ºã§ã™ãŒã€ã“ã®ã‚µã‚¤ã‚ºã¸ã®ç¸®å°å‡¦ç†ãŒæ¯å›è¡Œã‚ã‚Œã¦ã„ã¦åŠ¹ç‡ãŒæ‚ªã„ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã¨ã®å…¼ã­åˆã„ã‚‚ã‚ã‚Šã¾ã™ãŒã€äº‹å‰ã«å‡¦ç†ã§ãã‚‹ã®ã§ã‚ã‚Œã°é«˜é€ŸåŒ–ã§ãã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
    * **ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã¨ãƒ˜ãƒƒãƒ‰ã®å­¦ç¿’ã‚’åˆ†é›¢ã™ã‚‹:** ã“ã‚Œã‚‚ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã¨ã®å…¼ã­åˆã„ãŒã‚ã‚Šã¾ã™ãŒã€ç”»åƒã‚’äºˆã‚ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã‚’ä½¿ã£ã¦ç‰¹å¾´é‡ã«å¤‰æ›ã—ã¦ãŠã‘ã°ã€ãƒ˜ãƒƒãƒ‰ã®ã¿ã®å­¦ç¿’ã§æ¸ˆã¿ã¾ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹å ´åˆã¯ã€ã‚‚ã¡ã‚ã‚“ã“ã®æ‰‹æ®µã¯ä½¿ãˆã¾ã›ã‚“ã€‚

# å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦

å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ã€è¦æœ›ãŒã‚ã‚Œã°å…¬é–‹ã—ã¾ã™ã€‚16MBã»ã©ã‚ã‚‹ã®ã§ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç½®ã‘ã‚‹å ´æ‰€ã®ææ¡ˆã‚‚å«ã¾ã‚Œã¦ã„ã‚‹ã¨å¬‰ã—ã„ã§ã™ã€‚

# ä»Šå›ã¯ã“ã“ã¾ã§

ã¤ã„ã«å­¦ç¿’ã¾ã§åˆ°é”ã—ã¾ã—ãŸã€‚ä»Šå¾Œã¯ã€ãƒ©ãƒ™ãƒ«ä»˜ã‘ã€é«˜ç²¾åº¦åŒ–ã€é«˜é€ŸåŒ–ã€è©•ä¾¡ã€æ¨è«–ã€è’¸ç•™ãªã©ã«ã¤ã„ã¦æ›¸ããŸã„ã¨æ€ã£ã¦ã„ã¾ã™ã€‚ä»Šæ—¥ã¯ã“ã“ã¾ã§ï¼

ã€Œ[ã‘ã—ã‹ã‚‰ã‚“ç”»åƒåˆ†é¡å™¨ã‚’ä½œã£ã¦ã¿ã‚‹ (9) æ¨è«–](202104-pornography-classifier-9)ã€ã«ç¶šãã€‚
