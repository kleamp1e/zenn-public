---
title: "EfficientNet B0ã€œB7ã§ç”»åƒåˆ†é¡å™¨ã‚’è»¢ç§»å­¦ç¿’ã—ã¦ã¿ã‚‹"
emoji: "ğŸ“"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["machinelearning", "deeplearning", "computervision", "python", "keras"]
published: false
---

# ã¯ã˜ã‚ã«

ã€Œ[ã‘ã—ã‹ã‚‰ã‚“ç”»åƒåˆ†é¡å™¨ã‚’ä½œã£ã¦ã¿ã‚‹](202102-pornography-classifier-1)ã€ã‚·ãƒªãƒ¼ã‚ºã§ã€ç”»åƒåˆ†é¡ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦EfficientNetã‚’ä½¿ã£ã¦ã¿ã¾ã—ãŸã€‚
ä»Šå›ã¯EfficientNetã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã§ã‚ã‚‹B0ã€œB7ã«ã¤ã„ã¦ã€å®Ÿéš›ã«å­¦ç¿’ã‚’è¡Œã£ã¦ã€å®Ÿä¾‹ã§ã®ç›¸é•ã‚’è¦‹ã¦ã„ãã¾ã™ã€‚

# ãƒ‡ãƒ¼ã‚¿

ä½¿ç”¨ã—ãŸç”»åƒãƒ‡ãƒ¼ã‚¿ã«ã¯1ã‚¯ãƒ©ã‚¹ã®ãƒ©ãƒ™ãƒ«ï¼ˆ`0`ã¨`1`ã®2å€¤åˆ†é¡ï¼‰ãŒä»˜ã‘ã‚‰ã‚Œã¦ãŠã‚Šã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã€æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¯8:1:1ã®æ¯”ç‡ã«è¿‘ã¥ãã‚ˆã†ã«ãƒãƒƒã‚·ãƒ¥å€¤ãƒ™ãƒ¼ã‚¹ã§åˆ‡ã‚Šå‡ºã—ã¦ã„ã¾ã™ã€‚
ã¾ãŸã€æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦ã¯ãƒ©ãƒ™ãƒ«æ•°ãŒåŒæ•°ã«ãªã‚‹ã‚ˆã†ã«èª¿æ•´ã—ã¦ã„ã¾ã™ã€‚

ãƒ‡ãƒ¼ã‚¿æ•°ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

| ç¨®åˆ¥ | ãƒ©ãƒ™ãƒ«`0` | ãƒ©ãƒ™ãƒ«`1` | åˆè¨ˆ |
|:---|---:|---:|---:|
| å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ | 6,126 | 13,532 | 19,658 |
| æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ | 747 | 747 | 1,494 |
| ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ | 744 | 744 | 1,488 |
| åˆè¨ˆ | 7,617 | 15,023 | 22,640 |

# ç’°å¢ƒ

ä½¿ç”¨ã—ãŸç’°å¢ƒã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚å­¦ç¿’ã¯Dockerã‚³ãƒ³ãƒ†ãƒŠå†…ã§å®Ÿæ–½ã—ã¦ã„ã¾ã™ã€‚

* ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢:
    * CPU: AMD Ryzen 7 3700Xï¼ˆ8ã‚³ã‚¢/16ã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰
    * ãƒ¡ãƒ¢ãƒª: 64GB
    * GPU: GeForce GTX 1070ï¼ˆãƒ¡ãƒ¢ãƒª8GBï¼‰
* ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢:
    * OS: Ubuntu 20.04.2 LTS
    * Docker: 19.03.8
    * NVIDIAãƒ‰ãƒ©ã‚¤ãƒ: 460.39
    * Dockerã‚³ãƒ³ãƒ†ãƒŠå†…:
        * CUDA: 11.0.3
        * cuDNN: 8
        * Python: 3.8.5
        * TensorFlow: 2.4.1

# ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

æ©Ÿæ¢°å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¨ã—ã¦ã¯ã€ŒKerasã€ã‚’ä½¿ç”¨ã—ã¾ã—ãŸã€‚
Kerasã§ã¯ã€TensorFlow Hubã‹ã‚‰å–å¾—ã—ãŸEfficientNetã®å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ç°¡å˜ã«ä½¿ã†ã“ã¨ãŒã§ãã¾ã™ã€‚

# å­¦ç¿’çµæœ

ãã‚Œãã‚Œã®ãƒ¢ãƒ‡ãƒ«ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦1å›ãšã¤ã€10ã‚¨ãƒãƒƒã‚¯ã®è»¢ç§»å­¦ç¿’ã‚’è¡Œã„ã€çµæœã¯ä»¥ä¸‹ã®é€šã‚Šã§ã—ãŸã€‚
Bxã®æ•°å­—ãŒå¤§ãããªã‚‹ã«ã¤ã‚Œã¦ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãããªã‚Šã¾ã™ãŒã€ãã‚Œã«å¿œã˜ã¦ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ã—ãŸç²¾åº¦ãŒé«˜ã¾ã‚Šã€å­¦ç¿’æ™‚é–“ãŒå»¶ã³ã‚‹çµæœã¨ãªã‚Šã¾ã—ãŸã€‚

æœ€å°ã®B0ã¨æœ€å¤§ã®B7ã‚’æ¯”ã¹ã‚‹ã¨ã€ç²¾åº¦ã¯+5%ã€å­¦ç¿’æ™‚é–“ã¯31å€ã¨ãªã‚Šã¾ã—ãŸã€‚

| ãƒ¢ãƒ‡ãƒ« | ç”»åƒã‚µã‚¤ã‚º [px] | ãƒãƒƒãƒã‚µã‚¤ã‚º | ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° | ãƒ†ã‚¹ãƒˆLoss | B0ã¨ã®å·® | ãƒ†ã‚¹ãƒˆç²¾åº¦ | B0ã¨ã®å·® | å­¦ç¿’æ™‚é–“ | B0ã¨ã®å€ç‡ |
|:---|---:|---:|---:|---:|---:|---:|---:|---:|---:|---:|
| EfficientNet B0 | 224 | 512 | 16,493,696 |  4,050,845 | 0.3236 | -       | 0.8516 | -      |   9m48.603s |  1.0 |
| EfficientNet B1 | 240 | 256 | 26,702,696 |  6,576,513 | 0.2958 | -0.0278 | 0.8781 | +0.027 |  12m29.039s |  1.3 |
| EfficientNet B2 | 260 | 256 | 31,477,888 |  7,769,971 | 0.2696 | -0.0540 | 0.8750 | +0.023 |  15m38.572s |  1.6 |
| EfficientNet B3 | 300 | 128 | 43,586,544 | 10,785,065 | 0.2599 | -0.0637 | 0.8864 | +0.035 |  24m24.092s |  2.5 |
| EfficientNet B4 | 380 | 128 | 71,244,456 | 17,675,609 | 0.2387 | -0.0849 | 0.8991 | +0.048 |  49m44.266s |  5.1 |
| EfficientNet B5 | 456 | 64 | 114,713,416 | 28,515,569 | 0.2347 | -0.0889 | 0.9042 | +0.053 |  98m26.809s | 10.0 |
| EfficientNet B6 | 528 | 32 | 164,599,656 | 40,962,441 | 0.2351 | -0.0885 | 0.9042 | +0.053 | 177m17.915s | 18.1 |
| EfficientNet B7 | 600 | 32 | 257,306,968 | 64,100,241 | 0.2382 | -0.0854 | 0.9076 | +0.056 | 306m44.716s | 31.3 |

å…±é€šã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãªã©ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

* ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ï¼ˆBackboneï¼‰: EfficientNet
* ãƒ˜ãƒƒãƒ‰ï¼ˆHeadï¼‰: å…¨çµåˆå±¤ï¼ˆFC: Fully Connectedï¼‰ + Sigmoid
* ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ï¼ˆOptimizerï¼‰: Adam
* ã‚¨ãƒãƒƒã‚¯æ•°: 10

ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®æ¯”è¼ƒã‚’ä»¥ä¸‹ã«ç¤ºã—ã¾ã™ã€‚

![](https://storage.googleapis.com/zenn-user-upload/wvcv0s080an02jwfn19wktw6ebw5)

ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ã—ãŸç²¾åº¦ã¨Losså€¤ã®æ¯”è¼ƒã‚’ä»¥ä¸‹ã«ç¤ºã—ã¾ã™ã€‚

![](https://storage.googleapis.com/zenn-user-upload/rjwmytnxadunuu1phhf1zunnkt7s)

ç²¾åº¦ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®æ¯”è¼ƒã‚’ä»¥ä¸‹ã«ç¤ºã—ã¾ã™ã€‚B1ã¨B2ãŒå…¥ã‚Œæ›¿ã‚ã£ã¦ã„ã¾ã™ãŒèª¤å·®ã®ç¯„å›²å†…ã‹ã¨æ€ã„ã¾ã™ã€‚

![](https://storage.googleapis.com/zenn-user-upload/pu51ingqie3oryoo6rta2il38mg0)

å„ãƒ¢ãƒ‡ãƒ«ã«ãŠã‘ã‚‹ç²¾åº¦ã€Losså€¤ã«ã¤ã„ã¦ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã€æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã«ãŠã‘ã‚‹å¤‰é·ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚

![](https://storage.googleapis.com/zenn-user-upload/7rs4ppl0n5rx18f97nkn25hbxm7s)

# å­¦ç¿’å‡¦ç†

å­¦ç¿’ã«ä½¿ç”¨ã—ãŸPythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ã€‚B0ã€œB7ã«ã¤ã„ã¦ã€ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã—ã¦ã„ã‚‹ç®‡æ‰€ã‚’èª¿æ•´ã—ã¤ã¤å®Ÿè¡Œã—ã¾ã—ãŸã€‚

```py
#!/usr/bin/env python3

import datetime

import pandas as pd
import tensorflow as tf
import tensorflow_hub as hub

BATCH_SIZE = 512 # B0
# BATCH_SIZE = 256 # B1, B2
# BATCH_SIZE = 128 # B3, B4
# BATCH_SIZE = 64 # B5
# BATCH_SIZE = 32 # B6, B7

TARGET_SIZE = 224 # B0
# TARGET_SIZE = 240 # B1
# TARGET_SIZE = 260 # B2
# TARGET_SIZE = 300 # B3
# TARGET_SIZE = 380 # B4
# TARGET_SIZE = 456 # B5
# TARGET_SIZE = 528 # B6
# TARGET_SIZE = 600 # B7

EPOCHS = 10

model = tf.keras.Sequential(
    [
        hub.KerasLayer(
            "https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1", # B0
            # "https://tfhub.dev/tensorflow/efficientnet/b1/feature-vector/1", # B1
            # "https://tfhub.dev/tensorflow/efficientnet/b2/feature-vector/1", # B2
            # "https://tfhub.dev/tensorflow/efficientnet/b3/feature-vector/1", # B3
            # "https://tfhub.dev/tensorflow/efficientnet/b4/feature-vector/1", # B4
            # "https://tfhub.dev/tensorflow/efficientnet/b5/feature-vector/1", # B5
            # "https://tfhub.dev/tensorflow/efficientnet/b6/feature-vector/1", # B6
            # "https://tfhub.dev/tensorflow/efficientnet/b7/feature-vector/1", # B7
            trainable=False,
        ),
        tf.keras.layers.Dense(1, activation="sigmoid"),
    ]
)
model.build([None, TARGET_SIZE, TARGET_SIZE, 3])
model.compile(
    optimizer=tf.keras.optimizers.Adam(),
    loss="binary_crossentropy",
    metrics=["accuracy"],
)
model.summary()

train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=(1.0 / 255))
train_generator = train_datagen.flow_from_directory(
    "/tmp/cache/pornography/train",
    target_size=(TARGET_SIZE, TARGET_SIZE),
    batch_size=BATCH_SIZE,
    class_mode="binary",
)

validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=(1.0 / 255)
)
validation_generator = validation_datagen.flow_from_directory(
    "/tmp/cache/pornography/validation",
    target_size=(TARGET_SIZE, TARGET_SIZE),
    batch_size=BATCH_SIZE,
    class_mode="binary",
)

test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=(1.0 / 255))
test_generator = test_datagen.flow_from_directory(
    "/tmp/cache/pornography/test",
    target_size=(TARGET_SIZE, TARGET_SIZE),
    batch_size=BATCH_SIZE,
    class_mode="binary",
)

model.fit(
    x=train_generator,
    steps_per_epoch=train_generator.n // BATCH_SIZE,
    epochs=EPOCHS,
    workers=8,
    validation_data=validation_generator,
    validation_steps=validation_generator.n // BATCH_SIZE,
    callbacks=[
        tf.keras.callbacks.TensorBoard(
            log_dir="log/" + datetime.datetime.now().strftime("%Y%m%d_%H%M%S"),
            histogram_freq=1,
        )
    ],
)

model.evaluate(x=test_generator, steps=(test_generator.n // BATCH_SIZE), workers=8)

model.save("model.h5")
```

# æœ€å¾Œã«

ä»Šå›ã®çµæœã‚’è¦‹ã‚‹é™ã‚Šã€B3ã€B4ã‚ãŸã‚ŠãŒå­¦ç¿’æ™‚é–“ã¨ç²¾åº¦ã®ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„ã‹ãªã¨æ€ã„ã¾ã—ãŸã€‚

ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸå ´åˆã®ç›¸é•ã«ã¤ã„ã¦ã‚‚ã€ã„ã¤ã‹èª¿ã¹ã¦ã¿ãŸã„ã¨æ€ã„ã¾ã™ã€‚
